{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d86f6cd",
   "metadata": {},
   "source": [
    "# Web Search with LlamaIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4168e6b6",
   "metadata": {},
   "source": [
    "This example shows how to use the Python [LlamaIndex](https://docs.llamaindex.ai/en/stable/) library to run a text-generation request on open-source LLMs and embedding models using the OpenAI SDK, then augment that request using results from Google web search.\n",
    "\n",
    "### <u>Requirements</u>\n",
    "1. As you will accessing the LLMs and embedding models through Vector AI Engineering's Kaleidoscope Service (Vector Inference + Autoscaling), you will need to request a KScope API Key:\n",
    "\n",
    "      Run the following command (replace ```<user_id>``` and ```<password>```) from **within the cluster** to obtain the API Key. The ```access_token``` in the output is your KScope API Key.\n",
    "  ```bash\n",
    "  curl -X POST -d \"grant_type=password\" -d \"username=<user_id>\" -d \"password=<password>\" https://kscope.vectorinstitute.ai/token\n",
    "  ```\n",
    "2. After obtaining the `.env` configurations, make sure to create the ```.kscope.env``` file in your home directory (```/h/<user_id>```) and set the following env variables:\n",
    "- For local models through Kaleidoscope (KScope):\n",
    "    ```bash\n",
    "    export OPENAI_BASE_URL=\"https://kscope.vectorinstitute.ai/v1\"\n",
    "    export OPENAI_API_KEY=<kscope_api_key>\n",
    "    ```\n",
    "- For OpenAI models:\n",
    "   ```bash\n",
    "   export OPENAI_BASE_URL=\"https://api.openai.com/v1\"\n",
    "   export OPENAI_API_KEY=<openai_api_key>\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e4da1f",
   "metadata": {},
   "source": [
    "## Set up the RAG workflow environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9a8826-fcd8-439b-8c5d-f9047fbe5c0e",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea754e1b-3f61-4562-839f-a999db8e926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f637730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import os\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from googlesearch import search\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from llama_index.core import Settings, VectorStoreIndex, StorageContext\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core.node_parser import LangchainNodeParser\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.readers import StringIterableReader\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai_like import OpenAILike\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ae9862-6b55-4556-b38a-fc7ba55ee37f",
   "metadata": {},
   "source": [
    "#### Load config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fac6ed4-691d-4669-b72b-1ceb4d27944d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add root folder of the rag_bootcamp repo to PYTHONPATH\n",
    "current_dir = Path().resolve()\n",
    "parent_dir = current_dir.parent\n",
    "sys.path.insert(0, str(parent_dir))\n",
    "\n",
    "from utils.load_secrets import load_env_file\n",
    "load_env_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c528521-8bb4-49c6-b181-e0ecd6862e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATOR_BASE_URL = os.environ[\"OPENAI_BASE_URL\"]\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ecf9ac",
   "metadata": {},
   "source": [
    "#### Set up some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd4e2417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"Document {i+1}:\\n\\n\" + d.text for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9e47ff-77bc-4ecd-9e7f-8abc60fa8d81",
   "metadata": {},
   "source": [
    "#### Choose LLM and embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84b28b5e-d9d9-4788-9887-5c71aedfd8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATOR_MODEL_NAME = \"Meta-Llama-3.1-8B-Instruct\"\n",
    "EMBEDDING_MODEL_NAME = \"bge-base-en-v1.5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e558afb",
   "metadata": {},
   "source": [
    "## Start with a basic generation request without RAG augmentation\n",
    "\n",
    "Let's start by asking Llama-3.1 a question about recent events that it doesn't know about, something that happened after it finished training. At the time I'm writing this notebook in November 2024, Llama3 doesn't know who won the last World Series of baseball.\n",
    "\n",
    "*Who won the 2024 World Series of baseball?*\n",
    "\n",
    "**The correct answer is the Los Angeles Dodgers won in October 2024.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6133a928",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Who won the 2024 World Series of baseball?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bccaf41",
   "metadata": {},
   "source": [
    "## Now send the query to the open source model using KScope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40c2663f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: \n",
      "\n",
      "assistant: I don't have the ability to predict the future or know the outcome of future events, including the 2024 World Series. The 2024 World Series has not yet occurred, and I don't have any information about it. I can provide information about past World Series winners, though. Would you like to know more about that?\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAILike(\n",
    "    model=GENERATOR_MODEL_NAME,\n",
    "    is_chat_model=True,\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    api_base=GENERATOR_BASE_URL,\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    api_version=\"1\"\n",
    ")\n",
    "message = [\n",
    "    ChatMessage(\n",
    "        role=\"user\",\n",
    "        content=query\n",
    "    )\n",
    "]\n",
    "try:\n",
    "    result = llm.chat(message)\n",
    "    print(f\"Result: \\n\\n{result}\")\n",
    "except Exception as err:\n",
    "    if \"Error code: 503\" in err.message:\n",
    "        print(f\"The model {GENERATOR_MODEL_NAME} is not ready yet.\")\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e1c200",
   "metadata": {},
   "source": [
    "Llama-3.1 admits that it doesn't know the answer, since according to the model it's a future event.\n",
    "\n",
    "Let's see how we can use RAG to augment our question with a Google web search and get the correct answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0255ea68",
   "metadata": {},
   "source": [
    "## Ingestion: Do a Google web search for the query and obtain the necessary information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9d0304",
   "metadata": {},
   "source": [
    "Parse through all the websites returned by a Google search, break them up into smaller digestible chunks, then encode them as vector embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5710c72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of source documents: 8\n",
      "Number of text chunks: 573\n"
     ]
    }
   ],
   "source": [
    "# Do a Google web search and store the results in a documents list\n",
    "web_documents = []\n",
    "for result_url in search(query):\n",
    "    response = requests.get(result_url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    web_documents.append(soup.get_text())\n",
    "\n",
    "docs = StringIterableReader().load_data(texts=web_documents)\n",
    "print(f\"Number of source documents: {len(docs)}\")\n",
    "\n",
    "# Split the documents into smaller chunks\n",
    "parser = LangchainNodeParser(RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=32))\n",
    "chunks = parser.get_nodes_from_documents(docs)\n",
    "print(f\"Number of text chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706de010-2ad6-4e89-a307-2ad30497fc07",
   "metadata": {},
   "source": [
    "#### Define the embeddings model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54f69ffb-44f0-411f-bdc3-75efe8fb0d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up the embeddings model bge-base-en-v1.5 from https://kscope.vectorinstitute.ai/v1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Setting up the embeddings model {EMBEDDING_MODEL_NAME} from {GENERATOR_BASE_URL}\")\n",
    "embeddings = OpenAIEmbedding(\n",
    "    model_name=EMBEDDING_MODEL_NAME,\n",
    "    embed_batch_size=128,\n",
    "    api_base=GENERATOR_BASE_URL,\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566f1024-90cf-424a-9372-9dec784bc258",
   "metadata": {},
   "source": [
    "#### Set LLM and embedding model [recommended for LlamaIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7484523-4a7d-43de-9c9c-bf46425e83ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = llm\n",
    "Settings.embed_model = embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736ed6a7-17a1-49f3-b406-bf7c3aec4595",
   "metadata": {},
   "source": [
    "## Retrieval: Make the document chunks available via a retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14a096b-85b9-45db-a9d6-dd1fde37358e",
   "metadata": {},
   "source": [
    "The retriever will identify the document chunks that most closely match our original query. (This takes about 1-2 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "996df356-db4f-4e1e-90cb-9414ed0d2ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embed_model_dim(embed_model):\n",
    "    embed_out = embed_model.get_text_embedding(\"Dummy Text\")\n",
    "    return len(embed_out)\n",
    "\n",
    "faiss_dim = get_embed_model_dim(embeddings)\n",
    "faiss_index = faiss.IndexFlatL2(faiss_dim)\n",
    "\n",
    "vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "index = VectorStoreIndex(chunks, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "891457d4-60cb-470c-b11a-3840eb85c882",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = index.as_retriever(similarity_top_k=5)\n",
    "\n",
    "# Retrieve the most relevant context from the vector store based on the query\n",
    "retrieved_docs = retriever.retrieve(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aa43e8-cf9b-42f2-bfb4-b12c00370480",
   "metadata": {},
   "source": [
    "Let's see what results it found. Important to note, these results are in the order the retriever thought were the best matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7dffa44d-c61c-4d35-835b-eb3aa9989f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "2024 World Series - Wikipedia\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Jump to content\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Main menu\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Main menu\n",
      "move to sidebar\n",
      "hide\n",
      "\n",
      "\n",
      "\n",
      "\t\tNavigation\n",
      "\t\n",
      "\n",
      "\n",
      "Main pageContentsCurrent eventsRandom articleAbout WikipediaContact us\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\tContribute\n",
      "\t\n",
      "\n",
      "\n",
      "HelpLearn to editCommunity portalRecent changesUpload file\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Search\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Search\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Appearance\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Donate\n",
      "\n",
      "Create account\n",
      "\n",
      "Log in\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Personal tools\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Donate Create account Log in\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "The 2024 World Series was the championship series of Major League Baseball's (MLB) 2024 season. The 120th edition of the World Series, it was a best-of-seven playoff between the National League (NL) champion Los Angeles Dodgers and the American League (AL) champion New York Yankees. It was the Dodgers' first World Series appearance and win since 2020, and the Yankees' first World Series appearance since 2009. The series began on October 25 and ended on October 30 with the Dodgers winning in five\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "MLB World Series 2024 Prize Money: How much will the MLB champions make?The MLB is about to end its 2024 season Only the World Series between the New York Yankees and the Los Angeles Dodgers remains ahead.The New York Yankees were crowned in the East Division and achieved the best record in the American League. The Cleveland Guardians took the Central, while the Houston Astros won the West Division. The Baltimore Orioles, the Detroit Tigers, and the Kansas City Royals were awarded the wild card tickets in\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "Dodgers beat Yankees to win 2024 World Series\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 5:\n",
      "\n",
      "2024 Major League Baseball season - Wikipedia\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Jump to content\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Main menu\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Main menu\n",
      "move to sidebar\n",
      "hide\n",
      "\n",
      "\n",
      "\n",
      "\t\tNavigation\n",
      "\t\n",
      "\n",
      "\n",
      "Main pageContentsCurrent eventsRandom articleAbout WikipediaContact us\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\tContribute\n",
      "\t\n",
      "\n",
      "\n",
      "HelpLearn to editCommunity portalRecent changesUpload file\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Search\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Search\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Appearance\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Donate\n",
      "\n",
      "Create account\n",
      "\n",
      "Log in\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Personal tools\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Donate Create account Log in\n"
     ]
    }
   ],
   "source": [
    "pretty_print_docs(retrieved_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e44d26-fccb-480e-9ad2-2c48aa7dcc92",
   "metadata": {},
   "source": [
    "## Now send the query to the RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab480021-1266-45c9-b4ba-45d4c22dd5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: \n",
      "\n",
      "The Los Angeles Dodgers won the championship.\n"
     ]
    }
   ],
   "source": [
    "query_engine = RetrieverQueryEngine(retriever=retriever)\n",
    "result = query_engine.query(query)\n",
    "print(f\"Result: \\n\\n{result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d727ce-487c-447a-91b1-56616b02f557",
   "metadata": {},
   "source": [
    "The model provides the correct answer based on the information from the web."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
