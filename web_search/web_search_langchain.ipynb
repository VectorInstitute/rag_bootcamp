{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d86f6cd",
   "metadata": {},
   "source": [
    "# Web Search with Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4168e6b6",
   "metadata": {},
   "source": [
    "This example shows how to use the Python [LangChain](https://python.langchain.com/docs/get_started/introduction) library to run a text-generation request on open-source LLMs and embedding models using the OpenAI SDK, then augment that request using results from Google web search.\n",
    "\n",
    "### <u>Requirements</u>\n",
    "1. As you will accessing the LLMs and embedding models through Vector AI Engineering's Kaleidoscope Service (Vector Inference + Autoscaling), you will need to request a KScope API Key:\n",
    "\n",
    "      Run the following command (replace ```<user_id>``` and ```<password>```) from **within the cluster** to obtain the API Key. The ```access_token``` in the output is your KScope API Key.\n",
    "  ```bash\n",
    "  curl -X POST -d \"grant_type=password\" -d \"username=<user_id>\" -d \"password=<password>\" https://kscope.vectorinstitute.ai/token\n",
    "  ```\n",
    "2. After obtaining the `.env` configurations, make sure to create the ```.kscope.env``` file in your home directory (```/h/<user_id>```) and set the following env variables:\n",
    "- For local models through Kaleidoscope (KScope):\n",
    "    ```bash\n",
    "    export OPENAI_BASE_URL=\"https://kscope.vectorinstitute.ai/v1\"\n",
    "    export OPENAI_API_KEY=<kscope_api_key>\n",
    "    ```\n",
    "- For OpenAI models:\n",
    "   ```bash\n",
    "   export OPENAI_BASE_URL=\"https://api.openai.com/v1\"\n",
    "   export OPENAI_API_KEY=<openai_api_key>\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e4da1f",
   "metadata": {},
   "source": [
    "## Set up the RAG workflow environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfd9616-af8c-4374-9e0e-2752341c6105",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fa9b3f3-9154-414e-b1bc-42bb4577ac54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f637730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from googlesearch import search\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ced0d04-2d3a-46c4-b74a-8f655f5918a3",
   "metadata": {},
   "source": [
    "#### Load config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3972a311-eedd-40af-8a05-ed99949654df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add root folder of the rag_bootcamp repo to PYTHONPATH\n",
    "current_dir = Path().resolve()\n",
    "parent_dir = current_dir.parent\n",
    "sys.path.insert(0, str(parent_dir))\n",
    "\n",
    "from utils.load_secrets import load_env_file\n",
    "load_env_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c2d6b52-7ad1-478e-be82-36bedfa505db",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATOR_BASE_URL = os.environ[\"OPENAI_BASE_URL\"]\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ecf9ac",
   "metadata": {},
   "source": [
    "#### Set up some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd4e2417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ff46fc-1897-4163-ae1d-15f05d1c863b",
   "metadata": {},
   "source": [
    "#### Choose LLM and embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd9e704-2c8f-41ac-b733-05b32d2caf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATOR_MODEL_NAME = \"Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "## Select one of the two options: \n",
    "## - \"all-MiniLM-L6-v2\" (22M parameters)\n",
    "## - \"bge-base-en-v1.5\" (110M parameters)\n",
    "\n",
    "# EMBEDDING_MODEL_NAME = \"bge-base-en-v1.5\"\n",
    "EMBEDDING_MODEL_NAME = \"all-MiniLM-L6-v2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e558afb",
   "metadata": {},
   "source": [
    "## Start with a basic generation request without RAG augmentation\n",
    "\n",
    "Let's start by asking Llama-3.1 a question about recent events that it doesn't know about, something that happened after it finished training. At the time I'm writing this notebook in November 2024, Llama3 doesn't know who won the last World Series of baseball.\n",
    "\n",
    "*Who won the 2024 World Series of baseball?*\n",
    "\n",
    "**The correct answer is the Los Angeles Dodgers won in October 2024.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6133a928",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Who won the 2024 World Series of baseball?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bccaf41",
   "metadata": {},
   "source": [
    "## Now send the query to the open source model using KScope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40c2663f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: \n",
      "\n",
      "I don't have the ability to predict the future or know the outcome of future events, including the 2024 World Series. The 2024 World Series has not yet occurred, and I don't have any information about it. I can provide information about past World Series winners, though. Would you like to know more about that?\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=GENERATOR_MODEL_NAME,\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    base_url=GENERATOR_BASE_URL,\n",
    "    api_key=OPENAI_API_KEY\n",
    ")\n",
    "message = [\n",
    "    (\"human\", query),\n",
    "]\n",
    "try:\n",
    "    result = llm.invoke(message)\n",
    "    print(f\"Result: \\n\\n{result.content}\")\n",
    "except Exception as err:\n",
    "    if \"Error code: 503\" in err.message:\n",
    "        print(f\"The model {GENERATOR_MODEL_NAME} is not ready yet.\")\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e1c200",
   "metadata": {},
   "source": [
    "Llama-3.1 admits that it doesn't know the answer, since according to the model it's a future event.\n",
    "\n",
    "Let's see how we can use RAG to augment our question with a Google web search and get the correct answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0255ea68",
   "metadata": {},
   "source": [
    "## Ingestion: Do a Google web search for the query and obtain the necessary information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9d0304",
   "metadata": {},
   "source": [
    "Parse through all the websites returned by a Google search, break them up into smaller digestible chunks, then encode them as vector embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5710c72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of source documents: 10\n",
      "Number of text chunks: 869\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Do a Google web search and parse the results into a big text string\n",
    "web_documents = []\n",
    "for result_url in search(query):\n",
    "    response = requests.get(result_url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    web_documents.append(soup.get_text())\n",
    "\n",
    "# Wrap text as Document object\n",
    "docs = [Document(page_content=web_txt, metadata={\"source\": \"web\"}) for web_txt in web_documents]\n",
    "print(f\"Number of source documents: {len(docs)}\")\n",
    "\n",
    "# Split the result text into smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=32)\n",
    "chunks = text_splitter.split_documents(docs)\n",
    "print(f\"Number of text chunks: {len(chunks)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce30b89-b89d-493c-bc2e-f0e3663f0bf4",
   "metadata": {},
   "source": [
    "#### Define the embeddings model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81a0f241-a654-4ab2-8851-57a23e063e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up the embeddings model all-MiniLM-L6-v2 at https://kscope.vectorinstitute.ai/v1\n"
     ]
    }
   ],
   "source": [
    "model_kwargs = {'device': 'cuda', 'trust_remote_code': True}\n",
    "encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n",
    "\n",
    "print(f\"Setting up the embeddings model {EMBEDDING_MODEL_NAME} at {GENERATOR_BASE_URL}\")\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=EMBEDDING_MODEL_NAME,\n",
    "    # Leverage the RoBERTa tokenizer to make sure that \n",
    "    # the chunks stay within the 512-token context window.\n",
    "    tiktoken_model_name=\"roberta-base\",\n",
    "    tiktoken_enabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59402fb-b900-47bd-aa2b-401eba290c10",
   "metadata": {},
   "source": [
    "## Retrieval: Make the document chunks available via a retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bfc4e4-4c62-492d-a0b5-9de6d6985a0d",
   "metadata": {},
   "source": [
    "The retriever will identify the document chunks that most closely match our original query. \n",
    "\n",
    "Depending on the number of chunks provided, generating the embeddings might require:\n",
    "- about 5 minutes, when using \"bge-base-en-v1.5\" (110M parameters);\n",
    "- about 1 minute, when using \"all-MiniLM-L6-v2\" (22M parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae20b23b-43ff-4677-a534-0f507b090d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# Retrieve the most relevant context from the vector store based on the query\n",
    "retrieved_docs = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cbba2a-9212-4179-b9e3-f8feb20be299",
   "metadata": {},
   "source": [
    "Let's see what results it found. Important to note, these results are in the order the retriever thought were the best matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bec4a394-cfe3-465f-9873-d86132bb47a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "The 2024 Major League Baseball season (MLB) began on March 20–21 with a two-game series between the Los Angeles Dodgers and the San Diego Padres held in Seoul, South Korea, before the regular season proper ran from March 28 to September 30.[1][2] The 94th All-Star Game was played on July 16 at Globe Life Field in Arlington, Texas,[3] with the American League winning, 5–3.[4] The postseason then began on October 1 and concluded with Game 5 of the World Series on October 30.[5] Going into the season, the\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "The 2024 Major League Baseball season (MLB) began on March 20–21 with a two-game series between the Los Angeles Dodgers and the San Diego Padres held in Seoul, South Korea, before the regular season proper ran from March 28 to September 30.[1][2] The 94th All-Star Game was played on July 16 at Globe Life Field in Arlington, Texas,[3] with the American League winning, 5–3.[4] The postseason then began on October 1 and concluded with Game 5 of the World Series on October 30.[5] Going into the season, the\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "^ \"Bart, Reynolds homer, Pirates beat White Sox 9-4\". ESPN.com. Associated Press. July 14, 2024. Chicago entered the day as the first team in MLB history with 70 losses before the All-Star break.\n",
      "\n",
      "^ Axisa, Mike (August 25, 2024). \"White Sox lose 100th game of 2024 MLB season: Chicago club on pace to beat 1962 Mets for most losses\". CBSSports.com. Retrieved August 25, 2024.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "^ \"Bart, Reynolds homer, Pirates beat White Sox 9-4\". ESPN.com. Associated Press. July 14, 2024. Chicago entered the day as the first team in MLB history with 70 losses before the All-Star break.\n",
      "\n",
      "^ Axisa, Mike (August 25, 2024). \"White Sox lose 100th game of 2024 MLB season: Chicago club on pace to beat 1962 Mets for most losses\". CBSSports.com. Retrieved August 25, 2024.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 5:\n",
      "\n",
      "The 2024 World Series was the championship series of Major League Baseball's (MLB) 2024 season. The 120th edition of the World Series, it was a best-of-seven playoff between the National League (NL) champion Los Angeles Dodgers and the American League (AL) champion New York Yankees. It was the Dodgers' first World Series appearance and win since 2020, and the Yankees' first World Series appearance since 2009. The series began on October 25 and ended on October 30 with the Dodgers winning in five\n"
     ]
    }
   ],
   "source": [
    "pretty_print_docs(retrieved_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2df3c5-d595-451e-aecb-117716936599",
   "metadata": {},
   "source": [
    "## Now send the query to the RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64b191b1-e25f-49e0-a377-e0b50023dd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: \n",
      "\n",
      "The Los Angeles Dodgers won the 2024 World Series.\n"
     ]
    }
   ],
   "source": [
    "rag_pipeline = RetrievalQA.from_llm(llm=llm, retriever=retriever)\n",
    "result = rag_pipeline.invoke(input=query)\n",
    "print(f\"Result: \\n\\n{result['result']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dc7d01-8605-4bcb-8078-e80d8b12dbed",
   "metadata": {},
   "source": [
    "The model provides the correct answer based on the information from the web."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
