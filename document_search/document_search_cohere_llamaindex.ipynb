{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d86f6cd",
   "metadata": {},
   "source": [
    "# Cohere Document Search with LlamaIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4168e6b6",
   "metadata": {},
   "source": [
    "This example shows how to use the Python [LlamaIndex](https://docs.llamaindex.ai/en/stable/) library to run a text-generation request against [Cohere's](https://cohere.com/) API, then augment that request using the text stored in a collection of local PDF documents.\n",
    "\n",
    "**Requirements:**\n",
    "- You will need an access key to Cohere's API key, which you can sign up for at (https://dashboard.cohere.com/welcome/login). A free trial account will suffice, but will be limited to a small number of requests.\n",
    "- After obtaining this key, store it in plain text in your home in directory in the `~/.cohere.key` file.\n",
    "- (Optional) Upload some pdf files into the `source_documents` subfolder under this notebook. We have already provided some sample pdfs, but feel free to replace these with your own."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e4da1f",
   "metadata": {},
   "source": [
    "## Set up the RAG workflow environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f637730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from llama_index import ServiceContext, SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.embeddings.cohereai import CohereEmbedding\n",
    "from llama_index.llms import Cohere\n",
    "from llama_index.postprocessor.cohere_rerank import CohereRerank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ecf9ac",
   "metadata": {},
   "source": [
    "Set up some helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd4e2417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9edd103",
   "metadata": {},
   "source": [
    "Make sure other necessary items are in place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74b61e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.environ[\"COHERE_API_KEY\"] = open(Path.home() / \".cohere.key\", \"r\").read().strip()\n",
    "    os.environ[\"CO_API_KEY\"] = open(Path.home() / \".cohere.key\", \"r\").read().strip()\n",
    "except Exception:\n",
    "    print(f\"ERROR: You must have a Cohere API key available in your home directory at ~/.cohere.key\")\n",
    "\n",
    "# Look for the source-materials folder and make sure there is at least 1 pdf file here\n",
    "contains_pdf = False\n",
    "directory_path = \"./source_documents\"\n",
    "if not os.path.exists(directory_path):\n",
    "    print(f\"ERROR: The {directory_path} subfolder must exist under this notebook\")\n",
    "for filename in os.listdir(directory_path):\n",
    "    contains_pdf = True if \".pdf\" in filename else contains_pdf\n",
    "if not contains_pdf:\n",
    "    print(f\"ERROR: The {directory_path} subfolder must contain at least one .pdf file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e558afb",
   "metadata": {},
   "source": [
    "## Start with a basic generation request without RAG augmentation\n",
    "\n",
    "Let's start by asking the Cohere LLM a difficult, domain-specific question we don't expect it to have an answer to. A simple question like \"*What is the capital of France?*\" is not a good question here, because that's basic knowledge that we expect the LLM to know.\n",
    "\n",
    "Instead, we want to ask it a question that is very domain-specific that it won't know the answer to. A good example would an obscure detail buried deep within a company's annual report. For example:\n",
    "\n",
    "\"*How many Vector scholarships in AI were awarded in 2022?*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6133a928",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How many Vector scholarships in AI were awarded in 2022?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358a22c5",
   "metadata": {},
   "source": [
    "## Now send the query to Cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00061d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: \n",
      "\n",
      " Vector Institute's scholarships page states that they award over 170 annual scholarships and awards. However, I am unable to find the exact number of Vector scholarships in AI that were awarded in 2022 in particular. \n",
      "\n",
      "These scholarships are offered to students pursuing a master's in AI at the University of Toronto with the Vector Institute. They are primarily based on merit and are intended to support students in their studies. \n",
      "\n",
      "Would you like to know more about these scholarships? \n"
     ]
    }
   ],
   "source": [
    "llm = Cohere(api_key=os.environ[\"COHERE_API_KEY\"])\n",
    "result = llm.complete(query)\n",
    "print(f\"Result: \\n\\n{result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e1c200",
   "metadata": {},
   "source": [
    "Without additional information, Cohere is unable to answer the question correctly. **Vector in fact awarded 109 AI scholarships in 2022.** Fortunately, we do have that information available in Vector's 2021-22 Annual Report, which is available in the `source_documents` folder. Let's see how we can use RAG to augment our question with a document search and get the correct answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0255ea68",
   "metadata": {},
   "source": [
    "## Ingestion: Load and store the documents from source-materials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9d0304",
   "metadata": {},
   "source": [
    "Start by reading in all the PDF files from `source_documents`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5710c72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of source materials: 42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the pdfs\n",
    "pdf_folder_path = \"./source_documents\"\n",
    "documents = SimpleDirectoryReader(pdf_folder_path).load_data()\n",
    "print(f\"Number of source materials: {len(documents)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a7545e",
   "metadata": {},
   "source": [
    "## Define an embeddings model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bc16fe",
   "metadata": {},
   "source": [
    "This embeddings model will convert the textual data from our PDF files into vector embeddings. These vector embeddings will later enable us to quickly find the chunk of text that most closely corresponds to our original query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1048c42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = CohereEmbedding(\n",
    "    model_name=\"embed-english-v3.0\",\n",
    "    input_type=\"search_query\"\n",
    ")\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    embed_model=embed_model,\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe1690e",
   "metadata": {},
   "source": [
    "## Storage: Store the documents in a vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "075ede5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ff8c7e4c334e1d85f0730e5b123059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c707d55041450e8baef046a0c3e4b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = VectorStoreIndex.from_documents(documents, service_context=service_context, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3008507b",
   "metadata": {},
   "source": [
    "## Retrieval: Now do a search to retrieve the chunk of document text that most closely matches our original query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23499f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search query retriever found 2 results\n",
      "First result example:\n",
      "Node ID: 6b66739f-c0f3-4ed2-a498-0eee12513166\n",
      "Text: 5  Annual Report 2021â€“22 Vector Institute SPOTLIGHT ON FIVE\n",
      "YEARS OF AI  LEADERSHIP FOR CANADIANS  SINCE THE VECTOR INSTITUTE WAS\n",
      "FOUNDED IN 2017:  2,080+  Students have graduated from  Vector-\n",
      "recognized AI programs and  study paths $6.2 M  Scholarship funds\n",
      "committed to  students in AI programs 3,700+  Postings for AI-focused\n",
      "jobs and  internsh...\n",
      "Score:  0.620\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search_query_retriever = index.as_retriever(service_context=service_context)\n",
    "search_query_retrieved_nodes = search_query_retriever.retrieve(query)\n",
    "print(f\"Search query retriever found {len(search_query_retrieved_nodes)} results\")\n",
    "print(f\"First result example:\\n{search_query_retrieved_nodes[0]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb632b45-b135-4561-9759-99fcc03e6959",
   "metadata": {},
   "source": [
    "That first result doesn't look right, but it's close? Could it be that we got the result that we wanted from that retrieval, but the results came back out of order? Let's try using a reranker to check which of our results is a closest match."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea847fe",
   "metadata": {},
   "source": [
    "## Reranking: Improve the ordering of the document chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24dd59e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reranker = CohereRerank()\n",
    "query_engine = index.as_query_engine(\n",
    "    node_postprocessors = [reranker]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef217bc",
   "metadata": {},
   "source": [
    "## Final RAG-augmented query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63696ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: The number of Vector Scholarships in AI awarded in 2022 is 109. \n",
      "\n",
      "This information can be found in the context information provided, under the section headed '26'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = query_engine.query(query)\n",
    "print(f\"Result: {result}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_dataloaders",
   "language": "python",
   "name": "rag_dataloaders"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
